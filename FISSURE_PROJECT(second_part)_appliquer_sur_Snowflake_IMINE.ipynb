{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lyes-Im/Imine_Lyes/blob/main/FISSURE_PROJECT(second_part)_appliquer_sur_Snowflake_IMINE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G607xmLQMrMZ",
      "metadata": {
        "id": "G607xmLQMrMZ"
      },
      "source": [
        "Projet fait par :\n",
        "IMINE Belaid Lyes\n",
        "\n",
        "Projet : Détection des fissure.\n",
        "\n",
        "## **2 ème partie du projet :**\n",
        "Voici les étapes en bref :\n",
        "\n",
        "**1.Préparation et gestion des données dans Snowflake**\n",
        "\n",
        "Afin de gérer efficacement un volume conséquent de données (11298 images de fissures), la plateforme Snowflake a été utilisée comme environnement centralisé de stockage et de calcul.\n",
        "\n",
        "Optimisation des fichiers :\n",
        "\n",
        "Les images sont stockées sous forme compressée (.gz), ce qui permet de :\n",
        "\n",
        "- réduire l’espace de stockage,\n",
        "\n",
        "- accélérer les transferts,\n",
        "\n",
        "- améliorer les performances de lecture pendant l’entraînement.\n",
        "\n",
        "**2.Choix de l’architecture : le modèle U-Net**\n",
        "\n",
        "Le problème traité dans ce projet une segmentation sémantique, où chaque pixel de l’image doit être classé comme fissure ou béton sain\n",
        "\n",
        "Le modèle U-Net est spécialisé pour ce genre de tache :\n",
        "\n",
        "- Il permet une localisation précise des fissures pixel par pixel.\n",
        "\n",
        "- Il est particulièrement performant pour détecter des structures fines et allongées, comme les fissures.\n",
        "\n",
        "- Son architecture à connexions de saut (skip connections) permet de préserver les détails spatiaux essentiels lors de la reconstruction du masque.\n",
        "\n",
        "**3.Entraînement et optimisation du modèle**\n",
        "L’apprentissage du modèle a été réalisé directement dans Snowflake à l’aide de PyTorch.\n",
        "\n",
        "- Fonction de perte (Loss) :\n",
        "\n",
        "  - Utilisation de fonctions adaptées à la segmentation binaire (ex. Binary Cross Entropy).\n",
        "\n",
        "  - Ce choix est important car les fissures représentent une très faible proportion des pixels, entraînant un fort déséquilibre entre les classes.\n",
        "\n",
        "- Suivi de l’apprentissage :\n",
        "\n",
        "    - Surveillance de la perte (loss) et de la métrique IoU (Intersection over Union).\n",
        "\n",
        "  - Mise en place d’un mécanisme d’early stopping afin d’éviter le surapprentissage.\n",
        "\n",
        "  - Enregistrer le meuilleur model trouvé avec un loss bas et IoU haut\n",
        "\n",
        "Ces stratégies permettent de garantir que le modèle apprend réellement la géométrie des fissures\n",
        "\n",
        "**4.Phase de test et diagnostic du modèle**\n",
        "\n",
        "Le modèle a ensuite été évalué sur un jeu de test  de 1 130 images.\n",
        "\n",
        "- Défi des données réelles :\n",
        "\n",
        "  - Une analyse approfondie du jeu de test a révélé qu’il est majoritairement composé d’images de béton sain (Support Fissure = 0).\n",
        "\n",
        "- Impact sur les métriques :\n",
        "\n",
        "  - Cette distribution explique des métriques globales faibles ou nulles, malgré est un  modèle fonctionnel vu que je l'ai testé sur les images d'entrainement.\n",
        "\n",
        "\n",
        "Cette seconde partie du projet met en évidence :\n",
        "\n",
        "- une intégration complète du deep learning dans Snowflake.\n",
        "- la maitrise de l'outil snowflake.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SpuJpUCgob6r",
      "metadata": {
        "id": "SpuJpUCgob6r"
      },
      "source": [
        "**Etape 01: Accès aux données avec Snowpark**\n",
        "\n",
        "Dans cette étape, nous utilisons Snowpark afin d’interagir directement avec Snowflake depuis le notebook.\n",
        "\n",
        "Nous définissons ici la base de données et le schéma de travail contenant la vue\n",
        "`V_TRAINING_DATA`, qui référence les images (URL), masques (URL) et image_groupe stockés dans un stage Snowflake.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3775908f-ca36-4846-8f38-5adca39217f2",
      "metadata": {
        "codeCollapsed": false,
        "id": "3775908f-ca36-4846-8f38-5adca39217f2",
        "language": "python",
        "name": "cell1"
      },
      "outputs": [],
      "source": [
        "# Import python packages\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# # Importation de Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "# Récupération de la session Snowflake active\n",
        "session = get_active_session()\n",
        "# Définition du contexte de travail (Database, schema)\n",
        "session.use_database(\"PROJET_FISSURES\")\n",
        "session.use_schema(\"STORAGE_SCHEMA\")\n",
        "\n",
        "# Chargement de la vue V_TRAINING_DATA dans un DataFrame Pandas\n",
        "try:\n",
        "    df_training = session.table(\"V_TRAINING_DATA\").to_pandas()\n",
        "    print(f\" {len(df_training)} lignes récupérées.\")\n",
        "except Exception as e:\n",
        "    print(f\" Erreur : {e}\")\n",
        "\n",
        "# Vérification du contenu\n",
        "df_training.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066de93b-03fd-46c1-a1e4-2b77d9dd23fa",
      "metadata": {
        "collapsed": false,
        "id": "066de93b-03fd-46c1-a1e4-2b77d9dd23fa",
        "name": "cell9"
      },
      "source": [
        "**Etape 02: Construction des paires image–masque internes au stage Snowflake**\n",
        "\n",
        "Les images et masques étant stockés sous forme de fichiers compressés (`.gz`)\n",
        "dans un stage Snowflake, nous devons construire des chemins internes compatibles\n",
        "avec l’environnement Snowflake ML.\n",
        "\n",
        "▶ Pour chaque groupe (TRAIN, VAL, TEST), nous générons une liste de paires\n",
        "(image, masque) pointant directement vers les fichiers stockés dans le stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee56640-a070-49a8-a152-11a13e2b8479",
      "metadata": {
        "id": "7ee56640-a070-49a8-a152-11a13e2b8479",
        "language": "python",
        "name": "cell10"
      },
      "outputs": [],
      "source": [
        "def get_internal_pairs(df, group_name):\n",
        "\n",
        "   \"\"\"\n",
        "    Construit les paires image–masque internes au stage Snowflake\n",
        "    pour un groupe donné (TRAIN, VAL ou TEST).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    pairs = []\n",
        "    # On filtre par groupe (TRAIN, VAL, TEST)\n",
        "    subset = df[df['IMAGE_GROUP'] == group_name]\n",
        "\n",
        "    for _, row in subset.iterrows():\n",
        "        # On construit le chemin interne au Stage\n",
        "\n",
        "        img_path = f\"@PROJET_FISSURES.STORAGE_SCHEMA.MY_FISSURE_STAGE/images/{row['IMAGE_NAME']}.gz\"\n",
        "        mask_path = f\"@PROJET_FISSURES.STORAGE_SCHEMA.MY_FISSURE_STAGE/masks/{row['MASK_NAME']}.gz\"\n",
        "\n",
        "        pairs.append((img_path, mask_path)) #Ajouter les pairs\n",
        "\n",
        "    return pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6592c56f-c0f6-4185-83b2-c735ee6895a4",
      "metadata": {
        "id": "6592c56f-c0f6-4185-83b2-c735ee6895a4",
        "language": "python",
        "name": "cell31"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "print(test_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lW4794X5wIKM",
      "metadata": {
        "id": "lW4794X5wIKM"
      },
      "source": [
        "### **Etape 03: Séparation des données par sous-ensemble**\n",
        "\n",
        "À partir de la vue Snowflake, les données sont déjà réparties en trois groupes :\n",
        "- TRAIN : données d’entraînement\n",
        "- VAL : données de validation\n",
        "- TEST : données de test\n",
        "\n",
        "Nous générons ici les listes finales de paires image–masque pour chaque sous-ensemble.\n",
        "\n",
        "   - (image,mask) :spécial training\n",
        "\n",
        "- (image,mask) :spécial validation\n",
        "\n",
        "- (image,mask) :spécial test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3547e17-2cd7-48e3-8071-db4e62c3de0a",
      "metadata": {
        "id": "b3547e17-2cd7-48e3-8071-db4e62c3de0a",
        "language": "python",
        "name": "cell6"
      },
      "outputs": [],
      "source": [
        "# On génère nos listes de paires en filtrant par TRAIN | VAL | TEST\n",
        "train_pairs = get_internal_pairs(df_training, 'TRAIN')\n",
        "val_pairs   = get_internal_pairs(df_training, 'VAL')\n",
        "test_pairs  = get_internal_pairs(df_training, 'TEST')\n",
        "\n",
        "print(f\" Paires constituées! Exemple de chemin : {train_pairs[0][0]}\")\n",
        "\n",
        "#Afficher la taille de train, test, validation -> pour objectif de confirmation de split\n",
        "print(f\"Train : {len(train_pairs)}\")\n",
        "print(f\"Val   : {len(val_pairs)}\")\n",
        "print(f\"Test  : {len(test_pairs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548085yJw_Hs",
      "metadata": {
        "id": "548085yJw_Hs"
      },
      "source": [
        "### **Etape 04: Lecture directe des images depuis le stage Snowflake et test de lecture image–masque**\n",
        "\n",
        "Snowflake ML permet de lire directement des fichiers stockés dans un stage,\n",
        "sans téléchargement local ni accès Internet (stockage sur Amazon S3).\n",
        "\n",
        "▶ Dans cette étape, nous testons la lecture des fichiers `.gz` contenant\n",
        "les images et les masques afin de vérifier que les données sont exploitables (sont bien chargée)\n",
        "pour l’entraînement du modèle.\n",
        "\n",
        "▶ Un test visuel est effectué sur une paire image–masque issue du jeu\n",
        "d’entraînement afin de confirmer la validité du chargement des données\n",
        "depuis le stage Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e554d2-700b-4a7a-b5ac-2ef4f4b9851e",
      "metadata": {
        "id": "01e554d2-700b-4a7a-b5ac-2ef4f4b9851e",
        "language": "python",
        "name": "cell12"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.files import SnowflakeFile\n",
        "import io\n",
        "import gzip\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_snowflake_gz_internal(path, is_mask=False):\n",
        "    try:\n",
        "        # SnowflakeFile.open ne nécessite pas d'internet\n",
        "        with SnowflakeFile.open(path, 'rb') as f:\n",
        "            # On décompresse le flux gzip\n",
        "            with gzip.GzipFile(fileobj=f) as gz:\n",
        "                img = Image.open(gz)\n",
        "                # Conversion selon le type :\n",
        "                # - masque en niveaux de gris\n",
        "                # - image couleur (RGB)\n",
        "                return img.convert(\"L\") if is_mask else img.convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur sur {path} : {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Test pour afficher la paire (image - mask) ---\n",
        "print(\"Test de lecture en cours...\")\n",
        "img_test = load_snowflake_gz_internal(train_pairs[0][0], is_mask=False)\n",
        "mask_test = load_snowflake_gz_internal(train_pairs[0][1], is_mask=True)\n",
        "#Affichage la paire (image - mask)\n",
        "if img_test and mask_test:\n",
        "    print(\"  Lire les images directement depuis le Stage.\")\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1); plt.imshow(img_test); plt.title(\"Image\")\n",
        "    plt.subplot(1, 2, 2); plt.imshow(mask_test, cmap='gray'); plt.title(\"Masque\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\" Erreur\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nDiHmgzT5EQ0",
      "metadata": {
        "id": "nDiHmgzT5EQ0"
      },
      "source": [
        "### **Etape 05:  Création d’un Dataset PyTorch personnalisé pour Snowflake**\n",
        "Dans cette étape, nous définissons une classe `Dataset` PyTorch permettant\n",
        "de charger dynamiquement les images et masques directement depuis\n",
        "le stage Snowflake.\n",
        "\n",
        "Chaque élément du dataset correspond à une paire (image, masque),\n",
        "chargée et transformée avant d’être envoyée au modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acf77fe-cbb3-4108-a984-74d7f5ffed47",
      "metadata": {
        "id": "4acf77fe-cbb3-4108-a984-74d7f5ffed47",
        "language": "python",
        "name": "cell7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class SnowflakeFissureDataset(Dataset):\n",
        "    def __init__(self, pairs, transform=None):\n",
        "        self.pairs = pairs\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      # Nombre total d'échantillons\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Récupération des chemins internes (@...)\n",
        "        img_path, mask_path = self.pairs[idx]\n",
        "\n",
        "        # Chargement depuis le stage Snowflake\n",
        "        image = load_snowflake_gz_internal(img_path, is_mask=False)\n",
        "        mask = load_snowflake_gz_internal(mask_path, is_mask=True)\n",
        "\n",
        "        # Application des transformations (Redimensionnement, Tenseurs)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HU3CvnSC6ZOs",
      "metadata": {
        "id": "HU3CvnSC6ZOs"
      },
      "source": [
        "### **Etape 05: Transformations des données**\n",
        "\n",
        "▶ Les images originales ayant une résolution élevée (448 x 448), elles sont redimensionnées\n",
        "en 256×256 pixels afin de réduire le temps de calcul tout en conservant\n",
        "une bonne précision de segmentation.\n",
        "\n",
        "▶ Les images sont ensuite converties en tenseurs PyTorch.\n",
        "\n",
        "▶ Création des datasets d’entraînement, de validation et de test\n",
        "à partir des paires image–masque précédemment construites.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812677c4-bd2a-41b6-bf58-3b39043d85e5",
      "metadata": {
        "id": "812677c4-bd2a-41b6-bf58-3b39043d85e5",
        "language": "python",
        "name": "cell11"
      },
      "outputs": [],
      "source": [
        "# --- Définition des transformations ---\n",
        "# On redimensionne à 256x256 car c'est un bon compromis vitesse/précision\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(), # Conversion en tenseur pytorch\n",
        "])\n",
        "\n",
        "# --- Instanciation des Datasets ---\n",
        "\n",
        "train_dataset = SnowflakeFissureDataset(train_pairs, transform=data_transforms) #Dataset training\n",
        "val_dataset   = SnowflakeFissureDataset(val_pairs,   transform=data_transforms) #Dataset validation\n",
        "test_dataset  = SnowflakeFissureDataset(test_pairs,  transform=data_transforms) #Dataset test\n",
        "\n",
        "\n",
        "print(f\"   - Train : {len(train_dataset)} images\")\n",
        "print(f\"   - Val   : {len(val_dataset)} images\")\n",
        "print(f\"   - Test  : {len(test_dataset)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Gx9LlMg7xgW",
      "metadata": {
        "id": "_Gx9LlMg7xgW"
      },
      "source": [
        "### **Etape 06: Configuration du GPU et des DataLoaders**\n",
        "\n",
        "Cette étape permet de :\n",
        "- détecter automatiquement la présence d’un GPU Snowflake (NVIDIA A10G)\n",
        "- définir les DataLoaders PyTorch pour l’entraînement, la validation et le test\n",
        "\n",
        "Les DataLoaders assurent le chargement par lots (batchs) des données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e71bff7e-06f0-452a-accf-a98c84e28160",
      "metadata": {
        "id": "e71bff7e-06f0-452a-accf-a98c84e28160",
        "language": "python",
        "name": "cell13"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Vérification du GPU Snowflake\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device détecté : {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\" Modèle de GPU : {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# 2. Configuration des DataLoaders\n",
        "# On utilise un batch_size de 16.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "#DataLoaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 3. Test ultime du loader\n",
        "# On essaie de récupérer un paquet d'images pour voir si tout s'enchaîne bien\n",
        "images, masks = next(iter(train_loader))\n",
        "\n",
        "print(f\"Prêt à envoyer {len(train_loader)} paquets de 16 images au modèle.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f102642-3f02-4240-a5af-80d0113705b5",
      "metadata": {
        "collapsed": false,
        "id": "5f102642-3f02-4240-a5af-80d0113705b5",
        "name": "cell15"
      },
      "source": [
        "### **Etape 07: Architecture du modèle ' *ResNet-UNet* '**\n",
        "\n",
        "Le modèle utilisé est une architecture hybride combinant :\n",
        "- un encodeur ResNet34\n",
        "- un décodeur de type U-Net\n",
        "\n",
        "Cette architecture est particulièrement adaptée aux tâches\n",
        "de segmentation d’images grâce à ses connexions de saut\n",
        "(skip connections).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc871e6-9dfc-4503-b38f-d9ff125b86fe",
      "metadata": {
        "id": "cdc871e6-9dfc-4503-b38f-d9ff125b86fe",
        "language": "python",
        "name": "cell14"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "         \"\"\"\n",
        "    Bloc standard U-Net : deux convolutions successives\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, n_classes=1):\n",
        "        super().__init__()\n",
        "        # Encodeur ResNet34 (sans poids pré-entraînés pour éviter l'erreur de connexion Internet)\n",
        "\n",
        "        resnet = models.resnet34(weights=None)\n",
        "\n",
        "        self.encoder0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)\n",
        "        self.pool0 = resnet.maxpool\n",
        "        self.encoder1 = resnet.layer1\n",
        "        self.encoder2 = resnet.layer2\n",
        "        self.encoder3 = resnet.layer3\n",
        "        self.encoder4 = resnet.layer4\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(512, 256)\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(128, 64)\n",
        "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e0 = self.encoder0(x)\n",
        "        e1 = self.encoder1(self.pool0(e0))\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "\n",
        "        d4 = self.up4(e4)\n",
        "        d4 = self.dec4(torch.cat([d4, e3], dim=1))\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([d3, e2], dim=1))\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([d2, e1], dim=1))\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([d1, e0], dim=1))\n",
        "\n",
        "        out = self.final(d1)\n",
        "        # Redimensionnement final\n",
        "        return F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc59057-91c1-410f-ab14-972bd8772b46",
      "metadata": {
        "collapsed": false,
        "id": "ccc59057-91c1-410f-ab14-972bd8772b46",
        "name": "cell18"
      },
      "source": [
        "### **Etape 08: Initialisation du model et entraînement du modèle**\n",
        "\n",
        "L’entraînement repose sur :\n",
        "- une fonction de perte BCEWithLogitsLoss\n",
        "- une métrique IoU (Intersection over Union)\n",
        "- un optimiseur Adam\n",
        "- une stratégie d’Early Stopping pour éviter le surapprentissage\n",
        "\n",
        "Une barre de progression est utilisée pour suivre l’évolution\n",
        "de l’entraînement en temps réel.\n",
        "\n",
        "▶ Après un certain nombre d'epoch, si on ne voit pas qu'il y a une augmentation d'IoU, on s'arrete et on enregistre le meilleur model pour l'utiliser dans l'étape de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08aa6ac6-67a4-4ab7-9e53-8be1a9d71d53",
      "metadata": {
        "id": "08aa6ac6-67a4-4ab7-9e53-8be1a9d71d53",
        "language": "python",
        "name": "cell16"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 11  # géré par Early Stopping\n",
        "learning_rate = 1e-4\n",
        "best_val_iou = 0.0\n",
        "patience = 7  # Nombre d'époques à attendre sans amélioration\n",
        "counter = 0\n",
        "\n",
        "model = ResNetUNet(n_classes=1).to(device)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def iou_score(outputs, masks, threshold=0.5):\n",
        "    outputs = torch.sigmoid(outputs)\n",
        "    outputs = (outputs > threshold).float()\n",
        "    intersection = (outputs * masks).sum()\n",
        "    union = outputs.sum() + masks.sum() - intersection\n",
        "    return (intersection + 1e-6) / (union + 1e-6)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_ious, val_ious = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf6b204-8a47-4ad6-950b-98a29d98ce59",
      "metadata": {
        "id": "ddf6b204-8a47-4ad6-950b-98a29d98ce59",
        "language": "python",
        "name": "cell19"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Boucle d'entraînement ---\n",
        "for epoch in range(num_epochs):\n",
        "    # --------- Entraînement ----------\n",
        "    model.train()\n",
        "    epoch_loss, epoch_iou = 0.0, 0.0\n",
        "\n",
        "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
        "    for images, masks in train_pbar:\n",
        "        images, masks = images.to(device), masks.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        current_iou = iou_score(outputs, masks).item()\n",
        "        epoch_iou += current_iou\n",
        "        train_pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'iou': f\"{current_iou:.4f}\"})\n",
        "\n",
        "    train_losses.append(epoch_loss / len(train_loader))\n",
        "    train_ious.append(epoch_iou / len(train_loader))\n",
        "\n",
        "    # --------- Validation ----------\n",
        "    model.eval()\n",
        "    val_loss, val_iou = 0.0, 0.0\n",
        "    torch.cuda.empty_cache() # Libère la mémoire pour la validation\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "        for images, masks in val_pbar:\n",
        "            images, masks = images.to(device), masks.to(device).float()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            current_val_iou = iou_score(outputs, masks).item()\n",
        "            val_iou += current_val_iou\n",
        "            val_pbar.set_postfix({'val_loss': f\"{loss.item():.4f}\", 'val_iou': f\"{current_val_iou:.4f}\"})\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_ious.append(val_iou / len(val_loader))\n",
        "\n",
        "    # Affichage des résultats de l'époque\n",
        "    print(f\"Epoch {epoch+1:02d}: Train Loss: {train_losses[-1]:.4f} | IoU: {train_ious[-1]:.4f} || Val Loss: {val_losses[-1]:.4f} | Val IoU: {val_ious[-1]:.4f}\")\n",
        "\n",
        "    # --------- Sauvegarde du meilleur modèle et Early Stopping ----------\n",
        "    if val_ious[-1] > best_val_iou:\n",
        "        best_val_iou = val_ious[-1]\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\" Nouveau meilleur modèle sauvegardé ! (IoU: {best_val_iou:.4f})\")\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping à l'époque {epoch+1}. Le modèle ne progresse plus.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e9ce37-bb43-43c3-bedf-d2e414cb5fb0",
      "metadata": {
        "collapsed": false,
        "id": "90e9ce37-bb43-43c3-bedf-d2e414cb5fb0",
        "name": "cell5"
      },
      "source": [
        "Le modèle améliore progressivement ses performances en IoU sur l’ensemble d’entraînement.\n",
        "La performance sur le jeu de validation atteint un maximum à l’epoch 7 (IoU = 0.37), avant de décroître, indiquant un début d’overfitting.\n",
        "Le modèle retenu est donc celui de l’epoch 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1c6bd4-24f3-4fed-9aef-22f328897951",
      "metadata": {
        "id": "fd1c6bd4-24f3-4fed-9aef-22f328897951",
        "language": "python",
        "name": "cell2"
      },
      "outputs": [],
      "source": [
        "# On récupère le meilleur model qui est stocké sur le STAGE.\n",
        "session.file.get(\"@MY_FISSURE_STAGE/models/best_model.pth\", os.getcwd())\n",
        "print(\"Fichier best_model.pth qui contient le model est récupéré du stage !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be60b4d-044c-4dce-8fea-355f8471d340",
      "metadata": {
        "collapsed": false,
        "id": "5be60b4d-044c-4dce-8fea-355f8471d340",
        "name": "cell23"
      },
      "source": [
        "J'avais une erreur sur le fichier 'best_model.pth.gz' qui est compressé, donc lors d'initaliser l'architecture et charger les poids, j'ai eu une erreur de type ( No such file or directory: 'best_model.pth')\n",
        "\n",
        "Décompresser le fichier :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017dc323-d28f-4a6d-b2fc-e3f82f3b1c35",
      "metadata": {
        "id": "017dc323-d28f-4a6d-b2fc-e3f82f3b1c35",
        "language": "python",
        "name": "cell22"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Décompression du fichier best_model.pth pour l'utiliser\n",
        "with gzip.open('best_model.pth.gz', 'rb') as f_in:\n",
        "    with open('best_model.pth', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"Fichier décompressé !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "481533f2-7e6a-4ff7-9c41-b575fa3132e2",
      "metadata": {
        "id": "481533f2-7e6a-4ff7-9c41-b575fa3132e2",
        "language": "python",
        "name": "cell3"
      },
      "outputs": [],
      "source": [
        "# Charger dans PyTorch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 1. Créer une instance vierge du modèle\n",
        "model_test = ResNetUNet(n_classes=1).to(device)\n",
        "\n",
        "\n",
        " # 2. Initialiser l'architecture et charger les poids\n",
        "model_test.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "model_test.eval()\n",
        "print(\"Modèle chargé depuis le Stage Snowflake et pret \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f403ff0-d0d4-46dc-9d8a-9c58a70a0116",
      "metadata": {
        "collapsed": false,
        "id": "7f403ff0-d0d4-46dc-9d8a-9c58a70a0116",
        "name": "cell20"
      },
      "source": [
        "## **Faire le test pour évaluer notre MODEL :**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Widw0KFbFLrd",
      "metadata": {
        "id": "Widw0KFbFLrd"
      },
      "source": [
        "### **Visualisation qualitative des résultats**\n",
        "\n",
        "Analyse visuelle\n",
        "des prédictions du modèle afin d’évaluer sa capacité à détecter correctement\n",
        "les fissures sur des images jamais vues.\n",
        "\n",
        "Pour cela, nous affichons :\n",
        "- l’image originale\n",
        "- le masque réel\n",
        "- le masque prédit par le modèle\n",
        "\n",
        "Chaque prédiction est accompagnée de son score **IoU** individuel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7b4201-ba84-4830-b6e9-045a2b586a78",
      "metadata": {
        "id": "2b7b4201-ba84-4830-b6e9-045a2b586a78",
        "language": "python",
        "name": "cell21"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_results(model, loader, num_samples=4):\n",
        "    model.eval()\n",
        "    images, masks = next(iter(loader))\n",
        "\n",
        "    # Inférence\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images.to(device))\n",
        "        preds = torch.sigmoid(outputs) > 0.5 # Seuil de détection\n",
        "\n",
        "    # Préparation de l'affichage\n",
        "    plt.figure(figsize=(15, 4 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Image originale (On dé-normalise si nécessaire ou on utilise permute)\n",
        "        plt.subplot(num_samples, 3, i*3 + 1)\n",
        "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image test {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Masque Réel (Ground Truth)\n",
        "        plt.subplot(num_samples, 3, i*3 + 2)\n",
        "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Fissures réelles \")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prédiction de l'IA\n",
        "        plt.subplot(num_samples, 3, i*3 + 3)\n",
        "        plt.imshow(preds[i].cpu().squeeze(), cmap='jet')\n",
        "        # Calcul de l'IoU individuel pour cette image\n",
        "        iou = iou_score(outputs[i:i+1], masks[i:i+1].to(device))\n",
        "        plt.title(f\"Détection IA (IoU: {iou:.4f})\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exécuter la visualisation\n",
        "visualize_results(model_test, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nB6HN3eTE9R6",
      "metadata": {
        "id": "nB6HN3eTE9R6"
      },
      "source": [
        "### Évaluation quantitative finale\n",
        "\n",
        "Afin de mesurer précisément la performance du modèle, une évaluation\n",
        "pixel par pixel est réalisée sur l’ensemble du jeu de test.\n",
        "\n",
        "Les métriques calculées sont :\n",
        "- Précision\n",
        "- Rappel\n",
        "- F1-score\n",
        "- Matrice de confusion globale\n",
        "\n",
        "Cette analyse permet de quantifier la capacité du modèle à distinguer\n",
        "les zones fissurées du béton sain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6189006b-1082-4434-a315-1c58149b6dac",
      "metadata": {
        "id": "6189006b-1082-4434-a315-1c58149b6dac",
        "language": "python",
        "name": "cell27"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "def compute_final_metrics(model, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    print(\"Analyse des 1130 images en cours...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in loader:\n",
        "            outputs = model(images.to(device))\n",
        "            # On transforme les probabilités en 0 ou 1 (seuil 0.5)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "\n",
        "            # On aplatit tout pour comparer pixel par pixel\n",
        "            y_true.extend(masks.view(-1).cpu().numpy())\n",
        "            y_pred.extend(preds.view(-1).cpu().numpy())\n",
        "\n",
        "    # 1. Calcul de la Matrice de Confusion\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # 2. Affichage des statistiques principales\n",
        "    print(\"\\n--- RAPPORT DE PERFORMANCE PIXEL ---\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['Béton Sain', 'Fissure']))\n",
        "\n",
        "    # 3. Visualisation de la Matrice de Confusion\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Sain (Prédit)', 'Fissure (Prédit)'],\n",
        "                yticklabels=['Sain (Réel)', 'Fissure (Réel)'])\n",
        "    plt.title(\"Matrice de Confusion (Total des Pixels)\")\n",
        "    plt.show()\n",
        "\n",
        "# Lancer le calcul final\n",
        "compute_final_metrics(model_test, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9072ad62-dfca-483a-8f27-55392f811638",
      "metadata": {
        "collapsed": false,
        "id": "9072ad62-dfca-483a-8f27-55392f811638",
        "name": "cell26"
      },
      "source": [
        "Le jeu de données de test fourni sur Snowflake (1 130 images) était déséquilibré et ne contenait que des images de béton sain (Support Fissure = 0). Les métriques de test montrent une spécificité élevée (détection du béton sain), mais pour évaluer réellement la détection des fissures, j'ai dû effectuer des tests manuels sur le jeu d'entraînement où le modèle a montré d'excellents résultats visuels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f52c349-fa90-4a76-94d7-744f40fcb8ca",
      "metadata": {
        "collapsed": false,
        "id": "7f52c349-fa90-4a76-94d7-744f40fcb8ca",
        "name": "cell24"
      },
      "source": [
        "### **Vérification sur le jeu d’entraînement**\n",
        "\n",
        "Une dernière visualisation est réalisée sur le jeu d’entraînement afin\n",
        "de vérifier que le modèle a bien appris à détecter les fissures connues.\n",
        "\n",
        "Cette étape permet de :\n",
        "- confirmer la capacité du modèle à apprendre.\n",
        "- identifier un éventuel sur-apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123ed7fc-b39c-4008-8bb0-a58ea860a974",
      "metadata": {
        "id": "123ed7fc-b39c-4008-8bb0-a58ea860a974",
        "language": "python",
        "name": "cell25"
      },
      "outputs": [],
      "source": [
        "# On utilise le TRAIN_LOADER car on sait qu'il contient des fissures\n",
        "print(\"Test sur le jeu d'entraînement pour vérifier notre model\")\n",
        "visualize_results(model_test, train_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "authorEmail": "",
      "authorId": "8941236240854",
      "authorName": "BULLFROG",
      "lastEditTime": 1767868959855,
      "notebookId": "5vkldsruz2ky3e5khjve",
      "sessionId": "67d81c3f-7817-460b-9351-166aeb36c827"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}